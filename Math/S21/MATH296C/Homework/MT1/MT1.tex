\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{array}
\usepackage{enumerate}
\usepackage{slashed}
\usepackage{colonequals}
\usepackage{fancyhdr}
\usepackage{enumitem}

\pagestyle{fancy}
\fancyhf{}
\rhead{Darcy}
\lhead{MATH 296C}
\rfoot{\thepage}
\setlength{\headheight}{10pt}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{prop}{Proposition}[section]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
%\theoremstyle{remark}
%\newtheorem*{remark}{Remark}
\newenvironment{solution}
{\renewcommand\qedsymbol{$\blacksquare$}\begin{proof}[Solution]}
{\end{proof}}

\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\bigabs}[1]{\Bigl \lvert #1 \Bigr \rvert}
\newcommand{\bigbracket}[1]{\Bigl [ #1 \Bigr ]}
\newcommand{\bigparen}[1]{\Bigl ( #1 \Bigr )}
\newcommand{\ceil}[1]{\lceil #1 \rceil}
\newcommand{\bigceil}[1]{\Bigl \lceil #1 \Bigr \rceil}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\bigfloor}[1]{\Bigl \lfloor #1 \Bigr \rfloor}
\newcommand{\norm}[1]{\| #1 \|}
\newcommand{\bignorm}[1]{\Bigl \| #1 \Bigr \| #1}
\newcommand{\inner}[1]{\langle #1 \rangle}
\newcommand{\set}[1]{{ #1 }}

\begin{document}
    \thispagestyle{empty}\hrule

    \begin{center}
        \vspace{.4cm} { \large MATH 296C}
    \end{center}
    {Name:\ Quin Darcy \hspace{\fill} Due Date: 3/9/21   \\
    { Instructor:}\ Dr. Krauel \hspace{\fill} Assignment:
    Midterm 1 \\ \hrule}

    \begin{enumerate}
        \item Consider the Lie algebra $L=\mathfrak{o}_4(\mathbb{C})$.
            \begin{enumerate}
                \item Find a basis and compute its dimension.
                    \begin{solution}
                        To find a basis we can start by considering some
                        $A\in\mathfrak{gl}_n(\mathbb{C})$ such that $A^t=-A$.
                        If we let 
                            \begin{equation*}
                                A = (a_{i,j})\in\text{Mat}_{n\times n}(\mathbb{C})
                            \end{equation*}
                        then we have that $A^t=(a_{j, i})$. Thus we need
                        entries such that $(a_{j, i})=-(a_{i, j})$. It follows
                        that the entries down the main diagonal must satisfy
                        $a_{i, i}=-a_{i, i}$ which implies $a_{i, j}=0$ for all
                        entries with $i=j$. For those entries not on the main
                        diagonal we have that the lower triangle is equal to
                        the negative of the upper triengle. Thus the general
                        form of the matrix can be written as 
                            \begin{equation*}
                                \begin{split}
                                    A =\begin{pmatrix}0&a&b&c\\-a&0&d&e\\-b&-d&0&f\\-c&-e&-f&0
                                    \end{pmatrix} 
                                    &=a\begin{pmatrix}0&1&0&0\\-1&0&0&0\\0&0&0&0\\0&0&0&0
                                    \end{pmatrix}+b\begin{pmatrix}0&0&1&0\\0&0&0&0\\-1&0&0&0\\0&0&0&0
                                    \end{pmatrix}+c\begin{pmatrix}0&0&0&1\\0&0&0&0\\0&0&0&0\\-1&0&0&0
                                    \end{pmatrix}\\&+d\begin{pmatrix}0&0&0&0\\0&0&1&0\\0&-1&0&0\\0&0&0&0
                                    \end{pmatrix}+e\begin{pmatrix}0&0&0&0\\0&0&0&1\\0&0&0&0\\0&-1&0&0
                                    \end{pmatrix}+f\begin{pmatrix}0&0&0&0\\0&0&0&0\\0&0&0&1\\0&0&-1&0
                                    \end{pmatrix}
                                \end{split}
                            \end{equation*}
                        With this it follows that $\text{dim}(\mathfrak{o}_4(\mathbb{C}))=6$.
                    \end{solution}
                \item Describe the trivial module and its dimension.
                    \begin{solution}
                        To obtain the trivial module we let
                        $L=\mathfrak{o}_4(\mathbb{C})$ and let $F=\mathbb{C}$
                        and define a map $L\times F\to F$ such that
                        $(x, a)\mapsto x.a:=0$, for all $x\in L$ and $a\in F$.
                        To show that this is a module, we let $x, y\in L$, $u,
                        v\in V$, and $\alpha, \beta\in F$. Then we have that 
                            \begin{equation*}
                                \begin{split}
                                    &(\alpha x+\beta y).u
                                    = 0 = \alpha(0)+\beta(0)=\alpha(x.u)+\beta(y.u)
                                    \\
                                    &x.(\alpha u+\beta
                                    v)=0=\alpha(0)+\beta(0)=\alpha(x.u)+\beta(x.v)
                                    \\
                                    &[x, y].u
                                    = 0 = x.(0)+y.(0)=x.(y.u)+y.(x.u).
                                \end{split}
                            \end{equation*}
                        As a module, then by Lemma 4.7, it is a representation
                        of $L$. Thus, with $F=\mathbb{C}$, then the trivial
                        representation is a 1-dimensional representation and
                        hence a 1-dimensional module.
                    \end{solution}\newpage
                \item Describe the natural module and its dimension.
                    \begin{solution}
                        As a subalgebra of $\mathfrak{gl}(\mathbb{C}^4)$, we
                        can define a map $\mathfrak{o}_4(\mathbb{C})\times
                        \mathbb{C}^4\to \mathbb{C}^4$ such that for any
                        $x\in\mathfrak{o}_c(\mathbb{C})$ and $(a, b, c, d)\in
                        \mathbb{C}^4$, where we let $v=(a, b, c, d)^T$, then
                        taking $x$ to be a basis element we get
                        \begin{equation*}
                            x.v=\begin{pmatrix}0&1&0&0\\-1&0&0&0\\0&0&0&0\\0&0&0&0\end{pmatrix}
                            \begin{pmatrix}a\\b\\c\\d \end{pmatrix}=
                            \begin{pmatrix}b\\-a\\0\\0 \end{pmatrix}. 
                        \end{equation*}
                        Finally, with $\mathbb{C}^4$ as our
                        $\mathfrak{o}_4(\mathbb{C})$-module, then we conclude
                        that the natural module is 4 dimensional.
                    \end{solution}
            \end{enumerate}
        \item Consider the Lie algebra $L=\mathfrak{sl}_3(\mathbb{C})$. Let
            $E_{ij}$ denote the $3\times 3$ matrix with a 1 in the $ij$-th
            entry, and zeros elsewhere. Set $H_1:=E_{11}-E_{22}$,
            $H_2:=E_{22}-E_{33}$, $X_1:=E_{12}$, $X_2:=E_{23}$,
            $X_{3}:=E_{13}$, $Y_1:=E_{21}$, $Y_2:=E_{32}$, $Y_3:=E_{31}$.
            \begin{enumerate}[label=(\alph*)]
                \item Compute $\text{ad}_{H_2}$ with respect to the basis above.
                    \begin{solution}
                        \begin{equation*}
                            \begin{split}
                                [H_2, H_1] &=
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}\begin{pmatrix}1&0&0\\0&-1&0\\0&0&0
                                \end{pmatrix}-\begin{pmatrix}1&0&0\\0&-1&0\\0&0&0\end{pmatrix}
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}=0 \\
                                [H_2, X_1] &=
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}\begin{pmatrix}0&1&0\\0&0&0\\0&0&0
                                \end{pmatrix}-\begin{pmatrix}0&1&0\\0&0&0\\0&0&0\end{pmatrix}
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}=-X_1 \\
                                [H_2, X_2] &=
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}\begin{pmatrix}0&0&0\\0&0&1\\0&0&0
                                \end{pmatrix}-\begin{pmatrix}0&0&0\\0&0&1\\0&0&0\end{pmatrix}
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix} = 2X_2 \\
                                [H_2, X_3] &=
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}\begin{pmatrix}0&0&1\\0&0&0\\0&0&0
                                \end{pmatrix}-\begin{pmatrix}0&0&1\\0&0&0\\0&0&0\end{pmatrix}
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}=X_3 \\
                                [H_2, Y_1] &=
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}\begin{pmatrix}0&0&0\\1&0&0\\0&0&0
                                \end{pmatrix}-\begin{pmatrix}0&0&0\\1&0&0\\0&0&0\end{pmatrix}
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}=Y_1 \\
                                [H_2, Y_2] &=
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}\begin{pmatrix}0&0&0\\0&0&0\\0&1&0
                                \end{pmatrix}-\begin{pmatrix}1&0&0\\0&1&0\\0&1&0\end{pmatrix}
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}=-2Y_2 \\
                                [H_2, Y_3] &=
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}\begin{pmatrix}0&0&0\\0&0&0\\1&0&0
                                \end{pmatrix}-\begin{pmatrix}0&0&0\\0&0&0\\1&0&0\end{pmatrix}
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1
                                \end{pmatrix}=-Y_3 \\ 
                            \end{split}
                        \end{equation*}
                    \end{solution}
                \item Consider the subset $\mathcal{H}=\text{span}\{H_1, H_2\}$
                    of $L$. Prove or disprove that $\mathcal{H}$ is an abelian
                    Lie subalgebra.
                    \begin{proof}
                        To prove that $\mathcal{H}$ is a Lie subalgebra, we
                        need to show that $\mathcal{H}$ is a subspace and $[x,
                        y]\in\mathcal{H}$ for all $x, y\in\mathcal{H}$.
                        Additionally, we need to show that $[x, y]=0$ for all
                        $x, y\in\mathcal{H}$.\par\hspace{4mm} First, we let
                        $x, y\in\mathcal{H}$ and let $c\in\mathbb{C}$. Then we
                        have that for some $\alpha, \beta, \gamma, \delta\in\mathbb{C}$
                        \begin{equation*}
                            \begin{split}
                                x &=
                                \alpha\begin{pmatrix}1&0&0\\0&-1&0\\0&0&0\end{pmatrix}+\beta
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1\end{pmatrix}=
                                \begin{pmatrix}\alpha&0&0\\0&\beta-\alpha&0\\0&0&-\beta\end{pmatrix}
                                \\
                                y&=\gamma\begin{pmatrix}1&0&0\\0&-1&0\\0&0&0\end{pmatrix}+\delta
                                \begin{pmatrix}0&0&0\\0&1&0\\0&0&-1\end{pmatrix}=
                                \begin{pmatrix}\gamma&0&0\\0&\delta-\gamma&0\\0&0&-\delta\end{pmatrix}
                            \end{split}
                        \end{equation*}
                        Now we observe that 
                        \begin{equation*}
                            \begin{split}
                                x+y&=\begin{pmatrix}\alpha&0&0\\0&\beta-\alpha&0\\0&0&-\beta\end{pmatrix}
                                +\begin{pmatrix}\gamma&0&0\\0&\delta-\gamma&0\\0&0&-\delta\end{pmatrix}\\
                                &=\begin{pmatrix}\alpha+\gamma&0&0\\0&(\beta+\delta)-(\alpha+\gamma)&0\\
                                0&0&-(\beta+\delta)\end{pmatrix} \\
                                &=(\alpha+\gamma)\begin{pmatrix}1&0&0\\0&-1&0\\0&0&0\end{pmatrix}+
                                (\beta+\delta)\begin{pmatrix}0&0&0\\0&1&0\\0&0&-1\end{pmatrix}\\
                                &=(\alpha+\gamma)H_1+(\beta+\delta)H_2\in\mathcal{H}.
                            \end{split}
                        \end{equation*}
                        Thus, $\mathcal{H}$ is closed under adition. Now we
                        look at 
                        \begin{equation*}
                            \begin{split}
                                kx = k(\alpha H_1+\beta H_2)=k\alpha
                                H_1+k\beta H_2\in\mathcal{H}.
                            \end{split}
                        \end{equation*}
                        Therefore, $\mathcal{H}$ is a subspace. 
                        To finish showing that $\mathcal{H}$ is a subalgebra, we
                        observe that 
                        \begin{equation*}
                            \begin{split}
                                [x, y] &= [\alpha H_1+\beta H_2, \gamma
                                H_1+\delta H_2] \\
                                &=[\alpha H_1, \gamma H_1]+[\alpha H_1, \delta
                                H_2]+[\beta H_2, \gamma H_1]+[\beta H_2, \delta
                                H_2] \\
                                &=(\alpha\gamma)[H_1, H_1]+(\alpha\delta)[H_1,
                                H_2]+(\beta\gamma)[H_2, H_1]+(\beta\delta)[H_2,
                                H_2] \\
                                &=(\alpha\gamma)(0)-(\alpha\delta)(0)
                                +(\beta\gamma)(0)+(\beta\delta)(0) \\
                                &=0\in\mathcal{H}.
                            \end{split}
                        \end{equation*}
                        The final line both completes the prove that
                        $\mathcal{H}$ is a subalgebra and it also proves that
                        $\mathcal{H}$ is abelian.
                    \end{proof}
                \item Prove or disprove that $\mathcal{H}$ is an ideal.
                    \begin{proof}
                        We will show that $\mathcal{H}$ is not an ideal.
                        Consider $H_2\in\mathcal{H}$ and
                        $Y_1\in\mathfrak{sl}_3(\mathbb{C})$. Then by part
                        2.(a), we have that $[H_2, Y_1]=Y_1$. If $\mathcal{H}$
                        were an ideal, then it would follow that
                        $Y_1\in\mathcal{H}$. However, this would imply that 
                        \begin{equation*}
                            Y_1=\begin{pmatrix}0&0&0\\1&0&0\\0&0&0\end{pmatrix}
                            =\begin{pmatrix}\alpha&0&0\\0&\beta-\alpha&0\\0&0&-\beta\end{pmatrix}  
                        \end{equation*}
                        for some $\alpha, \beta\in \mathbb{C}$, which is not
                        possible. Therefore, $\mathcal{H}$ is not an ideal.
                    \end{proof}
                \item Can you find a subalgebra of $L$ that is isomorphic to
                    $\mathfrak{sl}_2(\mathbb{C})$? If yes, find one and prove
                    that are isomorphic. If not, prove why not.
                    \begin{proof}
                        Yes. Consider the set $\text{span}(H_1, X_1, Y_1)$. We
                        claim that this is a subalgebra of $L$ and that it is
                        isomorphic to $\mathfrak{sl}_2(\mathbb{C})$. To see
                        that it is a subalgebra we first note that it is
                        a subspace since for any $u, v\in\text{span}(H_1, X_1,
                        Y_1)$, we have $\alpha_1, \alpha_2, \beta_2, \beta_2,
                        \gamma_1, \gamma_2\in \mathbb{C}$ such that 
                        \begin{equation*}
                            \begin{split}
                                u+v &= (\alpha_1 H_1+\beta_1 X_1+\gamma_1
                                Y_1)+(\alpha_2 H_1+\beta_2 X_2+\gamma_2 Y_2) \\
                                &=(\alpha_1+\alpha_2)H_1+(\gamma_1+\gamma_2)X_1
                                +(\beta_1+\beta_2)Y_1\\
                                \in\text{span}(H_1, X_1, Y_1).
                            \end{split}
                        \end{equation*}
                        Similarly, for any $k\in \mathbb{C}$, it follows that
                        $ku\in\text{span}(H_1, X_1, Y_1)$. Finally, we
                        calculate
                        \begin{equation*}
                            \begin{split}
                                [u, v] &= [\alpha_1 H_1+\beta_1 X_1+\gamma_1
                                Y_1, \alpha_2 H_1+\beta_2 X_1+\gamma_2 Y_1] \\
                                &=(\beta_1\gamma_2-\gamma_1\beta_2)H_1+
                                (2\alpha_1\beta_2-2\beta_1\alpha_2)X_1+
                                (2\gamma_1\alpha_2-2\alpha_1\gamma_2)Y_1 \\
                                &\in\text{span}(H_1, X_1, Y_1).
                            \end{split}
                        \end{equation*}
                        We also require that for any $v\in\text{span}(H_1, X_1,
                        Y_1)$, with $v=$Therefore the set is a subalgebra. Now we must show
                        that it is isomorphic to $\mathfrak{sl}_2(\mathbb{C})$.
                        To do this consider a linear map $\phi:\text{span}(H_1, X_1,
                        Y_1)\to\mathfrak{sl}_2(\mathbb{C})$ such that 
                        \begin{align*}
                            &H_1\mapsto h=\begin{pmatrix}1&0\\0&-1\end{pmatrix};&
                            &X_1\mapsto x=\begin{pmatrix}0&1\\0&0\end{pmatrix} ;&
                            &Y_1\mapsto y=\begin{pmatrix}0&0\\1&0\end{pmatrix} .
                        \end{align*}
                        With this map we must show that $\phi([x, y])=[\phi(x),
                        \phi(y)]$ for all $x, y\in\text{span}(H_1, X_1, Y_1)$.
                        So then let $x, y\in\text{span}(H_1, X_1, Y_1)$. Then
                        for $\alpha_1, \alpha_2, \beta_1, \beta_2, \gamma_1,
                        \gamma_2\in\mathbb{C}$, we have that 
                        \begin{equation*}
                            x = \alpha_1H_1+\beta_1X_1+\gamma_1Y_1\quad\text{and}\quad
                            y=\alpha_2H_1+\beta_2X_1+\gamma_2Y_1.
                        \end{equation*}
                        Thus by our calculation earlier we have
                        \begin{equation*}
                            \begin{split}
                                \phi([x, y]) &=
                                \phi((\beta_1\gamma_2-\gamma_1\beta_2)H_1
                                +(2\alpha_1\beta_2-2\beta_1\alpha_2)X_1
                                +(2\gamma_1\alpha_2-2\alpha_1\gamma_2)Y_1) \\
                                &=(\beta_1\gamma_2-\gamma_1\beta_2)\phi(H_1)
                                +(2\alpha_1\beta_2-2\beta_1\alpha_2)\phi(X_1)
                                +(2\gamma_1\alpha_2-\alpha_1\gamma_2)\phi(Y_1)
                                \\
                                &=(\beta_1\gamma_2-\gamma_1\beta_2)h
                                +(2\alpha_1\beta_2-2\beta_1\alpha_2)x
                                +(2\gamma_1\alpha_2-\alpha_1\gamma_2)y.
                            \end{split}
                        \end{equation*}
                        And we have that 
                        \begin{equation*}
                            \begin{split}
                                [\phi(x), \phi(y)] &=
                                [\phi(\alpha_1H_1+\beta_1X_1+\gamma_1Y_1),
                                \phi(\alpha_2H_1+\beta_2X_1+\gamma_2Y_1)] \\
                                &=[\alpha_1\phi(H_1)+\beta_1\phi(X_1)+\gamma_1\phi(Y_1),
                                \alpha_2\phi(H_1)+\beta_2\phi(X_1)+\gamma_2\phi(Y_1)]
                                \\
                                &=[\alpha_1 h+\beta_1 x+\gamma_1y, \alpha_2
                                h+\beta_2 x+\gamma_2 y] \\
                                &=
                                (2\alpha_1\beta_2)x-(2\alpha_1\gamma_2)y
                                -(2\beta_1\alpha_2)x+(\beta_1\gamma_2)h
                                +(2\gamma_1\alpha_2)y-(\gamma_1\beta_2)h \\
                                &=(\beta_1\gamma_2-\gamma_1\beta_2)h
                                +(2\alpha_1\beta_2-2\beta_1\alpha_2)x.
                                +(2\gamma_1\alpha_2-2\alpha_1\gamma_2)y
                            \end{split}
                        \end{equation*}
                        Therefore $\phi([x, y])=[\phi(x), \phi(y)]$ and $\phi$
                        is a Lie algebra homomorphism. Finally, we need to show
                        that $\phi$ is bijective. \par\hspace{4mm} Let
                        $v\in\mathfrak{sl}_2(\mathbb{C})$. Then for some
                        $\alpha, \beta, \gamma\in \mathbb{C}$, we have that
                        $v=\alpha h+\beta x+\gamma y$. Then letting $w=\alpha
                        H_1+\beta X_1+\gamma Y_1$, it follows that $\phi(w)=v$
                        and so $\phi$ is surjective. Now let $u\in\ker\phi$.
                        Then for some $\alpha, \beta, \gamma\in \mathbb{C}$
                        \begin{equation*}
                            \begin{split}
                                \phi(u)&=\phi(\alpha H_1+\beta X_1+\gamma Y_1)
                                \\
                                &=\alpha\phi(H_1)+\beta\phi(X_1)+\gamma\phi(Y_1)
                                \\
                                &=\alpha h+\beta x+\gamma y \\
                                &= 0,
                            \end{split}
                        \end{equation*}
                        which implies that $\alpha=\beta=\gamma=0$. Thus,
                        $\ker\phi=\{0\}$. Therefore, $\phi$ is injective.
                    \end{proof}
                \item Prove directly that $\mathfrak{sl}_3(\mathbb{C})$ is
                    a simple Lie algebra.
                    \begin{proof}
                        
                    \end{proof}
                \item Is the adjoint module of $\mathfrak{sl}_3(\mathbb{C})$ an
                    irreducible module?
                    \begin{solution}
                        Suppose that $U$ is a nonzero submodule of the
                        adjoint module of $\mathfrak{sl}_3(\mathbb{C})$. Then
                        $\text{dim}(U)\geq 1$. Assume that $\text{dim}(U)=1$.
                        Then it is spanned by one of the 8 basis elements.
                        Suppose it is spanned by $H_1$. As a submodule, we
                        require that $x.H_1=[x, H_1]\in U$ for all $x\in L$.
                        Thus, $[X_2, H_1]=X_2\in U$, implying that
                        $\text{dim}(U)>1$. Now suppose that $U$ is instead
                        spanned by $H_2$. Then $[X_1, H_2]=X_1\in U$, implying
                        the same contradiction. In fact we will find that for
                        the 6 remaining basis elements, we have that 
                        \begin{align*}
                            &[Y_3, X_1]=Y_2,& &[Y_2, X_2]=-H_2,& &[Y_2,
                            X_3]=-X_1, \\&[X_1, Y_1]=H_1,& &[X_2, Y_2]=H_2,&
                            &[X_2, Y_3]=Y_1.
                        \end{align*}
                    \end{solution}
                    The above implies that $\text{dim}(U)>1$. Similarly, if
                    $\text{dim}(U)=2$, then there are ${8\choose 2}=28$ possibilities in terms
                    of which 2 basis elements could span $U$. In each case we
                    find that a third basis element can be produced. The same
                    argument can be applied if $\text{dim}(U)=3,4,5,6,7$. This
                    fact follows from the calculation in 2.(a). That $X_1, X_2,
                    X_3, Y_1, Y_2, Y_3$ occurs, then so long as $U$ contains
                    any one basis element, the rest can be shown to be in $U$,
                    implying that $U=\mathfrak{sl}_3(\mathbb{C})$. Hence, the
                    adjoint module is in fact irreducible.
            \end{enumerate}
        \item Let $V$ be a finite-dimensional vector space. A bilinear form
            $b:V\times V\to\mathbb{C}$ is said to be \textbf{symmetric} if
            $b(x, y)=b(y, x)$ for any $x, y\in V$. A symmetric bilinear form is
            \textbf{nondegenerate} if $b(x, y)=0$ for all $x\in V$ implies
            $y=0$. Let $L$ be a finite-dimensional complex Lie algebra. The
            \textbf{Killing form} on $L$ is defined as the function
            $\kappa:L\times L\to\mathbb{C}$ given by $\kappa(x,
            y):=\text{tr}(\text{ad}_x\circ\text{ad}_y)$.
            \begin{enumerate}[label=(\alph*)]
                \item Prove that $\kappa$ is a symmetric bilinear form.
                    \begin{proof}
                        We will first show that $\kappa$ is a bilinear form.
                        Letting $x, u, v, w\in L$ and $\alpha, \beta, \gamma,
                        \delta\in\mathbb{C}$, then since
                        $\text{ad}:L\to\mathfrak{gl}(L)$ is a Lie algebra
                        homomorphism (Lemma 2.12) and
                        $\mathfrak{gl}(V)\cong\mathfrak{gl}_n(\mathbb{C})$
                        (Proposition 1.34),
                        then it follows that
                        \begin{equation*}
                            \begin{split}
                                \text{ad}_{\alpha x+\beta
                                u}\circ\text{ad}_{\gamma v+\delta w}
                                &=(\text{ad}(\alpha x+\beta
                                u))\circ(\text{ad}(\gamma v+\delta w)) \\
                                &=(\alpha\text{ad}(x)+\beta\text{ad}(u))\circ(\gamma\text{ad}(v)+\delta\text{ad}(w))
                                \\
                                &=(\alpha\text{ad}(x)\circ\gamma\text{ad}(v))
                                +(\alpha\text{ad}(x)\circ\delta\text{ad}(w))\\&\quad\quad
                                +(\beta\text{ad}(u)\circ\gamma\text{ad}(v))
                                +(\beta\text{ad}(u)\circ\delta\text{ad}(w)) \\
                                &=(\text{ad}_{\alpha x}\circ\text{ad}_{\gamma
                                v})+(\text{ad}_{\alpha x}\circ\text{ad}_{\delta
                                w})\\&\quad\quad+(\text{ad}_{\beta
                                u}\circ\text{ad}_{\gamma v})+(\text{ad}_{\beta
                                u}\circ\text{ad}_{\delta w}).
                            \end{split}
                        \end{equation*}
                        Hence, 
                        \begin{equation*}
                            \begin{split}
                                \kappa(\alpha x+\beta u, \gamma v+\delta w) &=
                                \text{tr}(\text{ad}_{\alpha x+\beta
                                u}\circ\text{ad}_{\gamma v+\delta w}) \\
                                &= \text{tr}(\text{ad}_{\alpha
                                x}\circ\text{ad}_{\gamma
                                v})+\text{tr}(\text{ad}_{\alpha
                                x}\circ\text{ad}_{\delta w})\\&\quad\quad
                                +\text{tr}(\text{ad}_{\beta
                                u}\circ\text{ad}_{\gamma
                                v})+\text{tr}(\text{ad}_{\beta
                                u}\circ\text{ad}_{\delta w}) \\
                                &=\alpha\gamma\text{tr}(\text{ad}_x\circ\text{ad}_v)
                                +\alpha\delta\text{tr}(\text{ad}_{x}\circ\text{ad}_w)
                                \\
                                &\quad\quad
                                +\beta\gamma\text{tr}(\text{ad}_u\circ\text{ad}_v)
                                +\beta\delta\text{tr}(\text{ad}_u\circ\text{ad}_w)
                                \\
                                &=\alpha\gamma\kappa(x, v)+\alpha\beta\kappa(x,
                                w)+\beta\gamma\kappa(u,
                                v)+\beta\delta\kappa(u, w).
                            \end{split}
                        \end{equation*}
                        Therefore, $\kappa$ is bilinear.
                    \end{proof}
            \end{enumerate}
    \end{enumerate}
\end{document}
