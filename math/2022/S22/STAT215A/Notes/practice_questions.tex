\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{array}
\usepackage{enumerate}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{Darcy}
\lhead{STAT 215A}
\rfoot{\thepage}
\setlength{\headheight}{10pt}

\newenvironment{solution}
{\renewcommand\qedsymbol{$\blacksquare$}\begin{proof}[Solution]}
{\end{proof}}
\newenvironment{psmall}{\left(\begin{smallmatrix}}{\end{smallmatrix}\right)}

\begin{document}
\thispagestyle{empty}\hrule

    \begin{center}
        \vspace{.4cm} { \large STAT 215A}
    \end{center}
    {Name:\ Quin Darcy \hspace{\fill} Due Date: NONE   \\
    { Instructor:}\ Dr. Cetin \hspace{\fill} Assignment:
    PRACTICE \\ \hrule}

    \begin{enumerate} 
        \item Let $\Omega$ be a sample space for a particular
            experiment.  Moreover, let $A$ and $B$ be two proper subsets of
            $\Omega$.  
            \begin{enumerate}[(a)] 
                \item Show that $A\cup
                    =A\cup(B\backslash A)$.  \begin{proof} Let $x\in A\cup B$.
                        Then $x\in A$ or $x\in B$. If $x\notin A$, then $x\in
                        B\backslash A$ and thus $x\in A\cup (B\backslash A)$.
                        If $x\in A$, then $x\in A\cup (B\backslash A)$. Thus
                        $A\cup B\subset A\cup(B\backslash A)$. Let $x\in
                        A\cup(B\backslash A)$.  Then $x\in A$ or $x\in B$ and
                    $x\notin A$. If $x\in A$, then $x\in A\cup B$. If $x\notin
                A$, then $x\in B$ and so $x\in A\cup B$. Therefore $A\cup
            B=A\cup(B\backslash A)$.  \end{proof} \item If $A$ and $B$ are not
            disjoint, determine the $\sigma$-algebra generated by $A$ and $B$.
            \begin{proof} Any $\sigma$-algebra containing $A$ and $B$ must
                contain $A^c$ and $B^c$. It must contain $A\cup B$, $ A^c\cup
                B$, $A\cup B^c$, $A\cap B$, $A^c\cup B^c$.  Thus, the
                $\sigma$-algebra generated by $A$ and $B$ is given by
                \begin{equation*} \Omega=\{\varnothing, A, B, A^c, B^c, A\cup
                        B, A\cap B, A^c\cup B, A\cup B^c, A^c\cup B^c, A^c\cap
    B^c, X\}.  \end{equation*} \end{proof} \end{enumerate} \item Let $(\Omega,
    \mathcal{F})$ be a measurable space, and $B, A_1, A_2, \dots,
    \in\mathcal{F}$. Prove the following distributive laws:
    \begin{enumerate}[(a)] \item $B\cap\big(\bigcup_{k=1}^{\infty}A_k\big)
            =\bigcup_{k=1}^{\infty}(B\cap A_k)$.  \begin{proof} Let $S_1$
                denote the set on the left, and $S_2$ denote the set on the
                right. Let $x\in S_1$, then $x\in B$ and for some
                $t\in\mathbb{Z}^{+}$, $x\in A_t$. Thus, $x\in B\cap A_t$. Hence
                \begin{equation*} x\in B\cap
                    A_t\cup\big(\bigcup_{k=1}^{\infty}(B\cap
                    A_k))=\bigcup_{k=1}^{\infty}(B\cap A_k).  \end{equation*}
                    Thus $S_1\subset S_2$. Now let $x\in S_2$. Then for some
                    $t\in\mathbb{Z}^{+}$, $x\in B\cap A_t$. Hence
                    \begin{equation*} x\in B\cap
                        \big(\bigcup_{k=1}^{\infty}A_k\big).  \end{equation*}
                    Thus $S_2\subset S1$ and so $S_1=S_2$.  \end{proof} \item
                    $B\cup\big(\bigcap_{k=1}^{\infty}A_k\big)=\bigcap_{k=1}^{\infty}(B\cup
                    A_k)$.  \begin{proof} Let $S_1$ denote the set on the left
                        and $S_2$ denote the set on the right. Let $x\in S_1$.
                        Then $x\in B$ or $x\in A_k$ for every $k$. If $x\in B$,
                        then $x\in B\cup A_k$ for every $k$. Hence
                        \begin{equation*} x\in \bigcap_{k=1}^{\infty}(B\cup
                        A_k).  \end{equation*} Hence $x\in S_2$ and so
                        $S_1\subset S_2$. Now let $x\in S_2$. Then $x\in B\cup
                        A_k$ for every $k$. If $x\in B$, then $x\in
                        B\cup\big(\bigcap_{k=1}^{\infty}A_k\big)$.  If $x\in
                        A_k$ for every $k$, then $x\in
            \bigcap_{k=1}^{\infty}A_k$ and thus $x\in
B\cup\big(\bigcap_{k=1}^{\infty}A_k\big)$. Therefore $S_2\subset S_1$ and so
$S_1=S_2$.  \end{proof} \end{enumerate} \item Let $(\Omega, \mathcal{F})$ be
a measurable space, and $B$ be a nonempty subset of $\Omega$.
\begin{enumerate}[(a)] \item Let $L=\{B\cap A:A\in\mathcal{F}\}$. Show that $L$
        is a $\sigma$-algebra on $B$.  \begin{proof} (i) Since
            $\varnothing\in\mathcal{F}$, then $B\cap\varnothing=\varnothing\in
            L$. (ii) Let $E\in L$. Then for some $A'\in\mathcal{F}$, we have
            that $E=B\cap A'$.  We want to show that $B\backslash E\in L$, that
            is, we need some $A\in\mathcal{F}$ such that $B\backslash E=B\cap
            A$. Expanding this out we have that \begin{align*} x&\in
                B\backslash(B\cap A') \\ &\Leftrightarrow (x\in B)\land(x\notin
                B\land x\notin A') \\ &\Leftrightarrow (x\in B)\land(x\in(B\cap
                A')^c) \\ &\Leftrightarrow (x\in B)\land(x\in B^c\vee x\in
                A'^c) \\ &\Leftrightarrow(x\in B\land x\in B^c)\vee(x\in B\land
                x\in A'^c) \\ &\Leftrightarrow (x\in B\cap B^c)\vee(x\in B\cap
                A'^c) \\ &\Leftrightarrow x\in(B\cap B^c)\cup(B\cap A'^c) \\
            &\Leftrightarrow x\in B\cap A'^c.  \end{align*} Since
            $A'^c\in\mathcal{F}$, then this proves that if $E\in L$, then
            $E^c\in L$. (iii) Finally, let $E_1, E_2, \dots$ be a sequence of
            elements of $L$. Then for each $E_i$ in this sequence, there is
            some $A_i\in\mathcal{F}$ such that $E_{i}=B\cap A_i$. Hence
            \begin{align*} \bigcup_{k=1}^{\infty}E_k &=
                \bigcup_{k=1}^{\infty}(B\cap
                A_i)=B\cap\big(\bigcup_{k=1}^{\infty}A_k\big).  \end{align*}
                The last equality following from exercise 2.(a). Since each
                $A_1, A_2, \dots$ is a sequence of elements of $\mathcal{F}$,
                then the countable union of the sequence is also in
            $\mathcal{F}$. Thus \begin{equation*} \bigcup_{k=1}^{\infty}E_k\in
        L.  \end{equation*} Therefore $L$ is a $\sigma$-algebra on $B$.
    \end{proof} \item Let $L$ be as in part (a). Is $(\Omega, L)$ a measurable
    space? In other words, is $L$ a $\sigma$-algebra on $\Omega$?
    \begin{solution} As a counter example, let $\Omega=\{0, 1\}$ and let
        $\mathcal{F}=\{\varnothing, \Omega\}$. If $B=\{0\}$, then
        $L=\{\varnothing, \{0\}\}$ which is not a $\sigma$-algebra on $\Omega$
        since $\{0\}^c=\{1\}\notin L$ and so $L$ is not closed under
        complementations.  \end{solution} \end{enumerate} \item Complete the
        proof of the inclusion-exclusion formula for any two events $A$ and $B$
        in a probability space $(\Omega, \mathcal{F}, P)$: \begin{equation*}
            P(A\cup B)=P(A)+P(B)-P(A\cap B).  \end{equation*} \begin{proof} To
                prove this equality, we want to appeal to the property of
                a measure which states that the measure of a countable union of
                disjoint events is the countable sum of the measure of each
                event. First we want to re-express $A\cup B$ as union of
                disjoint sets. To do this we refer to exercise 1.(a) to write
                $A\cup B=A\cup(B\backslash A)$. So then letting $E_1=A$,
                $E_2=B\backslash A$, and $E_i=\varnothing$ for all $i>2$, then
                we have that \begin{align*}
                    P\big(\bigcup_{k=1}^{\infty}E_k\big)&=\sum_{k=1}^{\infty}P(E_k)
                    \\ &=P(A)+P(B\backslash
                    A)+P(\varnothing)+P(\varnothing)+\cdots \\
            &=P(A)+P(B\backslash(A\cap B))+0+0+\cdots \\ &=P(A)+P(B)-P(A\cap
    B).  \end{align*} This completes the proof for two events.  \end{proof}
\item Complete the inclusion-exclusion formula for any three events $A$, $B$,
    and $C$ in a probability space $(\Omega, \mathcal{F}, P)$:
    \begin{equation*} P(A\cup B\cup C)=P(A)+P(B)+P(C)-P(A\cap B)-P(A\cap
        C)-P(B\cap C)+P(A\cap B\cap C).  \end{equation*} \begin{proof} As we
            did in exercise 4, we want to re-express $A\cup B\cup C$ as a union
            of disjoint events. We have \begin{align*} A\cup B\cup C &= A\cup
                (B\cup C) \\ &=A\cup(B\cup(C\backslash B)) \\
            &=A\cup(B\cup(C\backslash B))\backslash A.  \end{align*} By
            exercise 4, it follows that \begin{align*} P(A\cup B\cup C) &=
                P(A\cup(B\cup(C\backslash B))\backslash A) \\
                &=P(A)+P((B\cup(C\backslash B))\backslash
                A)-P(A\cap(B\cup(C\backslash B))\backslash A) \\
                &=P(A)+P((B\cup(C\backslash B))\backslash A) \\ &=P(A)+P(B\cup
                (C\backslash B))-P(A\cap(B\cup (C\backslash B)) \\
                    &=P(A)+P(B)+P(C\backslash B)-P((A\cap B)\cup(A\cap
                    (C\backslash B))) \\ &=P(A)+P(B)+P(C)-P(B\cap C)-P(A\cap
                    B)-P(A\cap (C\backslash B)) \\ &=P(A)+P(B)+P(C)-P(A\cap
                    B)-P(B\cap C)-P((A\cap C)\backslash B) \\
                    &=P(A)+P(B)+P(C)-P(A\cap B)-P(B\cap C)-P((A\cap
            C)\backslash(A\cap B\cap C)) \\ &=P(A)+P(B)+P(C)-P(A\cap B)-P(A\cap
    C)-P(B\cap C)+P(A\cap B\cap C).  \end{align*} \end{proof} \item The general
    inclusion-exclusion formula for the union of a finite number of events. Let
    $\{A_k:k=1, 2, \dots, n\}$ be a collection of $n$ events in a probability
    space $(\Omega, \mathcal{F}, P)$. Then for each $n\in\mathbb{N}$,
    \begin{equation*} P\big(\bigcup_{k=1}^n
    A_k\big)=\sum_{k=1}^nP(A_k)-\sum_{i<j}P(A_i\cap A_j)+\sum_{i<j<k}P(A_i\cap
A_j\cap A_k)+\cdots+(-1)^{n+1}P\big(\bigcap_{n=1}^n A_k\big).  \end{equation*}
\begin{proof} Eh, just please do this one later. Maybe tomorrow morning. Base
    case is covered by exercise 4. Adding another set to the union you can
    break it down into a union of $n$ sets which is covered by the inductive
    hypothesis and a single set. Together this is essentially the case of
unioning two events together.  \end{proof} \item Boole's inequality. Let
$\{A_k\}_{k\in\mathbb{N}}$ be a sequence of events in a probability space
$(\Omega, \mathcal{F}, P)$.  \begin{enumerate}[(a)] \item Prove that
        $P\big(\bigcup_{k=1}^{n}A_k\big)\leq \sum_{k=1}^{n}P(A_k)$, for all
        $n\in\mathbb{N}$.  \begin{proof} We proceed by induction on $n$. Let
            $n=2$. Then if $A_1, A_2\in\mathcal{F}$, we have that
            \begin{equation*} P(A_1\cup A_2)=P(A_1)+P(A_2)-P(A_1\cap A_2)\leq
            P(A_1)+P(A_2).  \end{equation*} This verifies our base case. Now
            assume the hypothesis is true for some $n\geq 2$. Let $A_1, \dots,
            A_n, A_{n+1}\in\mathcal{F}$. Then \begin{align*}
            P\big(\bigcup_{k=1}^{n+1}A_k\big)
        =P\big(\big(\bigcup_{k=1}^{n}A_k\big)\cup A_{n+1}\big) \leq\sum_{k=1}^n
    P(A_k)+P(A_{n+1}) =\sum_{k=1}^{n+1}P(A_k).  \end{align*} Hence, the claim
    is true for all $n\in\mathbb{N}$.  \end{proof} \item Prove that
    $P\big(\bigcup_{k=1}^{\infty}A_k\big)\leq \sum_{k=1}^{\infty}P(A_k)$.
    \begin{proof} Let $n\in\mathbb{N}$ and $A_1, \dots, A_n\in\mathcal{F}$ and
        let $A_{n+k}=\varnothing$ for all $k\in\mathbb{N}$. Then we have
        a sequence $A_1, A_2, \dots$ of events in $\mathcal{F}$. From part (a)
        of this exercise it follows that \begin{align*}
            P\big(\bigcup_{k=1}^{\infty}A_k\big)
            &=P\big(\big(\bigcup_{k=1}^{n}A_k\big)
            \cup\big(\bigcup_{k=n+1}^{\infty}A_k\big)\big) \\ &\leq
            P\big(\bigcup_{k=1}^{n}A_k\big)+P\big(\bigcup_{k=n+1}^{\infty}A_k\big)
            \\ &\leq \sum_{k=1}^{n}P(A_k)+P(\varnothing) \\
            &=\sum_{k=1}^{n}P(A_k)+\sum_{k=n+1}^{\infty}0 \\
            &=\sum_{k=1}^{\infty}P(A_k).  \end{align*} \end{proof}
    \end{enumerate} \item We are given two urns, each containing a collection
    of colored balls. Urn I contians two white balls and three blue balls, and
    Urn II contains three white balls and four blue balls. Select one of the
    urns randomly and then draw a ball from that urn selected.
    \begin{enumerate}[(a)] \item Describe the sample space $\Omega$ for this
            experiment.  Is it an equiprobable space?  \begin{solution} Begin
                by letting $U_1, U_2$ denote the two urns. Then we can express
                their contents as \begin{align*} U_1&=\{w_{11}, w_{12}, b_{11},
                    b_{12}, b_{13}\} \\ U_2&=\{w_{21}, w_{22}, w_{23}, b_{21},
                        b_{22}, b_{23}, b_{24}\}.  \end{align*} Since any
                        outcome of this experiment is the selection of a single
                        ball, then the set of all possible outcomes is
                        $\Omega=U_1\cup U_2$. To show that this is an
                        equiprobable space, we have to show that it is finite
                        and that for all $\omega_i, \omega_j\in\Omega$, with
                        $i\neq j$, $P(\{\omega_i\})=P(\{\omega_j\})$, for some
                        probability measure $P$. First, we will let
                        $\mathcal{F}=\mathcal{P}(\Omega)$ be the
                        $\sigma$-algebra. Then define $P:\mathcal{F}\to[0,
                        \infty]$ by \begin{equation*} P(A)=\frac{|A|}{|\Omega|}
                        \end{equation*} for all $A\in\mathcal{F}$. It is clear
                        to see $P$ satisfies all three conditions of
                        a probability measure.\par\hspace{4mm} It also follows
                        that for any $\{\omega_i\}, \{\omega_j\}\in\mathcal{F}$
                        with $i\neq j$, that \begin{equation*}
                            P(\{\omega_i\})=\frac{|\{\omega_i\}|}{|\Omega|}
                            =\frac{1}{|\Omega|}
                    =\frac{|\omega_j|}{|\Omega|}=P(\{\omega_j\}).
            \end{equation*} Finally, since $\Omega$ is finite, then this proves
        that $(\Omega, \mathcal{F}, P)$ is an equiprobability space.
    \end{solution} \item What is the probability that the ball picked is blue?
    \begin{solution} The event of picking a blue ball can be expressed as the
        set \begin{equation*} B=\{b_{11}, b_{12}, b_{13}, b_{21}, b_{22},
            b_{23}, b_{24}\}.  \end{equation*} Since $B\subset\Omega$, then
        $B\in\mathcal{F}$ and therefore measureable. And so \begin{equation*}
    P(B)=\frac{|B|}{|\Omega|}=\frac{7}{12}.  \end{equation*} \end{solution}
\item Given that the ball picked is blue, what is the probability that it comes
    from Urn I?  \begin{solution} Let $A$ denote the event of selecting Urn
        I and let $B$ denote the event that a blue ball was selected. Then
        \begin{align*} A&=\{w_{11}, w_{12}, b_{11}, b_{12}, b_{13}\} \\
        B&=\{b_{11}, b_{12}, b_{13}, b_{21}, b_{22}, b_{23}, b_{24}\}.
    \end{align*} Thus the probability of $A$ given $B$ is \begin{equation*}
        P(A|B)=\frac{P(A\cap B)}{P(B)}=\frac{3}{7}.  \end{equation*}
        \end{solution} \end{enumerate} \item Using the same setup as in the
        previous exercise, now we draw a ball at random from Urn I, put it into
        Urn II and then pick a ball from Urn II.  \begin{enumerate}[(a)] \item
                What is the probability that both balls picked are blue?
                \begin{solution} There are two different approaches to this
                    problem. The first will use the following result: For any
                    events $A$ and $B$ such that $0<P(B)<1$, \begin{equation*}
                    P(A)=P(A\mid B)P(B)+P(A\mid B^c)P(B^c).  \end{equation*}
                    Letting $A$ denote the event that the last ball chosen is
                    blue and $B$ denote the event that the first ball chosen is
                    blue, then $P(B)=3/5$, $P(B^c)=2/5$, and \begin{align*}
                    &P(A\mid B)=\frac{5}{8} & &P(A\mid B^c)=\frac{1}{2}.
                \end{align*} Hence \begin{equation*}
                    P(A)=\frac{5}{8}\cdot\frac{3}{5}+\frac{1}{2}\cdot
                \frac{2}{5}=\frac{23}{40}.  \end{equation*} However this gives
                us the probability that the last ball chosen is blue. So we
                must subtract the probability that the first ball was white and
                the last ball was blue, which is $1/5$, and thus the
                probability that both balls were blue is $3/8$.\par\hspace{4mm}
                The second approach requires us to redefine a new $\Omega$
                based on the fact that we are making two choices, the latter
                being dependent on the former. Let \begin{equation*}
                \Omega=\bigcup_{\omega\in U_1}\{\omega\}\times
            U_2\cup\{\omega\}.  \end{equation*} Where the left side of the
            cartesian product represents our first choice from urn I and the
            right side represents urn II after adding our selected ball to it.
            Since adding a ball to urn II gives it a total of 8 elements, and
            there are
                        5 possible balls from urn I to add to urn II, then
                          $|\Omega|=5\cdot 8=40$. So then the events in which
                          both balls selected were blue is the set containing
                          a blue component in the left and right. For each blue
                          ball from urn I, of which there are 3, there
                          correpsonds 5 ordered pairs with the blue urn I ball
                          on the left and a blue urn II ball on the right.
                          Hence, there are a total of $3\cdot 5=15$ of these
                          ordered pairs.  Therefore, if $A$ is the event that
                      both the left and right components are blue, then
                  \begin{equation*} P(A)=\frac{15}{40}=\frac{3}{8}.
              \end{equation*} \end{solution} \item Given that the ball drawn
              from urn II was blue, what is the probability that the first ball
              drawn was also blue?  \begin{solution} Using the same setup as
                  the second half of part (a), we are interested in all the
                  times both the left and right components are blue out of all
                  the times the right components were blue. The latter count
                  would be $2\cdot 4=8$ for the cases in which we chose white
                  balls first, and $3\cdot 5=15$ for the cases in which we
                  chose blue balls first. Thus, there are 23 instances in which
                  a blue ball was chosen second. Of those, 15 of them include
                  the times in which a blue ball was chosen first. Hence, the
                  probability that the first ball was blue given that the
                  second ball was blue is $15/23$.  
              \end{solution}
  \end{enumerate} \end{enumerate} \end{document}
