\documentclass{article}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{authblk}
\usepackage{titlesec}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{array}
\usepackage{booktabs}
\usepackage{ragged2e}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{cleveref}
\usepackage{slashed}
\usepackage{commath}
\usepackage{lipsum}
\usepackage{colonequals}
\usepackage{addfont}
\usepackage{enumitem}
\usepackage{sectsty}
\usepackage{mathtools}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}

\usetikzlibrary{decorations.pathreplacing}
\usetikzlibrary{arrows.meta}


%\subsectionfont{\itshape}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\theoremstyle{definition}
\newtheorem{prop}{Proposition}[section]
\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\let\oldproofname=\proofname
\renewcommand{\proofname}{\bf{\textit{\oldproofname}}}

\newcommand{\closure}[2][3]{%
  {}\mkern#1mu\overline{\mkern-#1mu#2}}

\theoremstyle{definition}
\newtheorem{example}{Example}[section]

\newtheorem*{discussion}{Discussion}

\makeatletter
\renewenvironment{proof}[1][\proofname]{\par
  \pushQED{\qed}%
  \normalfont \topsep6\p@\@plus6\p@\relax
  \list{}{\leftmargin=0mm
          \rightmargin=0mm
          \settowidth{\itemindent}{\itshape#1}%
          \labelwidth=\itemindent
          \parsep=0pt \listparindent=0mm%\parindent 
  }
  \item[\hskip\labelsep
        \itshape
    #1\@addpunct{.}]\ignorespaces
}{%
  \popQED\endlist\@endpefalse
}

\newenvironment{solution}[1][\bf{\textit{Solution}}]{\par
  
  \normalfont \topsep6\p@\@plus6\p@\relax
  \list{}{\leftmargin=0mm
          \rightmargin=0mm
          \settowidth{\itemindent}{\itshape#1}%
          \labelwidth=\itemindent
          \parsep=0pt \listparindent=\parindent 
  }
  \item[\hskip\labelsep
        \itshape
    #1\@addpunct{.}]\ignorespaces
}{%
  \popQED\endlist\@endpefalse
}


\begin{document}

\title{Notes for Probability Theory}
\author{Quin Darcy}
\date{July 31, 2019}
\affil{\small{California State University, Sacramento}}
\maketitle

\section{A Motivating Example}

Imagine you are in a dusty old attic and in front of you sits three chests each with two drawers in them. You then recall once being told that one of the chests has a gold coin in each of its drawers, another chest has a gold coin in a drawer and a silver coin in the other drawer, and the last chest has one silver coin in each of its drawers. You are tasked to clean out the attic and so you must move all these chests to the truck outside. You begin by choosing a chest at random and after doing so you open one of its drawers. Inside this drawer you see a gold coin. Now you begin to wonder what kind of coin is in the second drawer. More specifically, you wonder what is the probability that a gold coin is in the second drawer.\par 
At first thought you might think that there are two chests that contain at least one gold coin and so there is either a silver coin in the second drawer or a gold coin. Thus, the probability of it being a gold coin must be 1/2. Sadly, this is incorrect and below we will learn how to calculate the probability correctly.

\vspace{4mm} The following contains a large amount of unquoted passages from the book \textit{Introduction to Probability Theory} by Hoel, Port, and Stone circa 1971.


The purpose presently is to develop a formal mathematical structure that forms the foundation for the mathematical treatment of random phenomena. We will begin by envisioning some experiment (like the one in the beginning) that we want to model. The first step is to identify the possible outcomes of this experiment. After deciding on these outcomes we choose a set $\Omega$ whose points $\omega$ are associated with these outcomes. Note that from a strictly mathematical point of view, $\Omega$ is just an abstract set of points.\par Next, we will take a nonempty collection $\mathcal{F}$ of subsets of $\Omega$ that is to represent the collection of ``events'' to which we wish to assign probabilities. By \textit{event} we mean a set $A$ in $\mathcal{F}$. Thus, to say \textit{the event $A$ occurs} means that the outcome of our experiment is represented by some point $\omega\in A$.\par Our next task is to decide what specifically is contained in the collection $\mathcal{F}$. To make this decision let us see what would be useful to include in $\mathcal{F}$. Suppose $A$ and $B$ are two events in $\mathcal{F}$. Recall that only events (i.e. elements of $\mathcal{F}$) will be assigned probabilities. Then it would be reasonable to not only want to know the probability of $A$ and $B$ individually, but we might also want to know the probability of either $A$ \textit{or} $B$ occurring and so to have a probability for this situation, it must be the case that $A\cup B\in\mathcal{F}$. Similarly, we might also want to know the probability of $A$ \textit{and} $B$ occurring and so for this situation to receive a probability, it must be an event, thus it must be the case that $A\cap B\in\mathcal{F}$. Okay, so it looks like a reasonable requirement for the elements of $\mathcal{F}$ is that if $A,B\in\mathcal{F}$, then $A\cup B\in\mathcal{F}$ and $A\cap B\in\mathcal{F}$. In other words, we require $\mathcal{F}$ to be closed under finite union and finite intersection. Is this all we need? Maybe not ... it seems just as relevant to want to know the probability of an event $A$ \textit{not} occurring. Thus, for each set $A\in\mathcal{F}$, we should also have its complement $A^{c}\in\mathcal{F}$.\par We have thus arrived at the conclusion that $\mathcal{F}$ should be a nonempty collection of subsets of $\Omega$ having the following properties: 

\begin{enumerate}[label=(\roman*)]
    \item If $A$ is in $\mathcal{F}$, then $A^{c}$ is in $\mathcal{F}$. 
    \item If $A$ and $B$ are in $\mathcal{F}$, then $A\cup B\in\mathcal{F}$ and $A\cap B\in\mathcal{F}$.
\end{enumerate}

\noindent It is easily shown by Induction that if $A_1, A_2,\dots, A_n$ are in $\mathcal{F}$, then so is $\bigcup_{i=1}^{n} A_i$ and $\bigcap_{i=1}^{n} A_i$. Additionally, we see that since $A\cap A^{c}=\varnothing$ and $A\cup A^{c}=\Omega$, then it follows that $\varnothing\in\mathcal{F}$ and $\Omega\in\mathcal{F}$. So far this seems to be a pretty sufficient set of requirements for $\mathcal{F}$. However, as we will see later on, our requirements need to be more stringent. Specifically, we not only want closure under finite set theoretic operations, but we want closure under countable infinite set theoretic operations. A collection of subsets of a given set $\Omega$ that is closed under countable set theoretic operations is called a $\sigma$-field of subsets of $\Omega$. More formally we have the following: 

\begin{definition}
    \textit{A nonempty collection of subsets $\mathcal{F}$ of a set $\Omega$ is called a $\sigma$-field of subsets of $\Omega$ provided that the following two properties hold:} 
    
    \begin{enumerate}[label=(\roman*)]
        \item \textit{If} $A\in\mathcal{F}$, \textit{then} $A^{c}\in\mathcal{F}$.
        \item \textit{If} $A_n\in\mathcal{F}$, \textit{where} $n=1,2,\dots$, \textit{then} $\bigcup_{i=1}^{\infty}A_i\in\mathcal{F}$ \textit{and} $\bigcap_{i=1}^{\infty} A_i\in\mathcal{F}$.
    \end{enumerate}
\end{definition}

Now that we have a formal definition, we move on to the task of assigning probabilities. Clearly, it makes sense to have a probability be represented by a nonnegative real number. Thus, for some event $A$, let $P(A)$ denote the probability of $A$, where $0\leq P(A)\leq 1$. It also follows that since $\Omega$ contains every possible outcome, then $P(\Omega)=1$. Next, it seems reasonable to require that if we have two disjoint events $A$ and $B$ (i.e., $A\cap B=\varnothing$), then $P(A\cup B)=P(A)+P(B)$. To see why this makes sense, consider a single coin toss. The outcome is either heads or tales, and any one of these events occurring negates the other and so these events are disjoint. So then to ask what the probability of either of them happening is simply the addition of their respective probabilities. This leads us to another definition:

\begin{definition}
    \textit{A probability measure $P$ on a $\sigma$-field of subsets of a set $\Omega$ is a real valued function having domain $\mathcal{F}$ satisfying the following properties:}
    
    \begin{enumerate}[label=(\roman*)]
        \item $P(\Omega)=1$.
        \item $P(A)\geq 0$ \textit{for all} $A\in\mathcal{F}$.
        \item \textit{If} $A_n$, \textit{where} $n=1,2,\dots$, \textit{are mutually disjoint sets in} $\mathcal{F}$, \textit{then}
        
        \begin{equation*}
            P\bigg(\bigcup_{n=1}^{\infty} A_n\bigg)=\sum_{n=1}^{\infty}P(A_n).
        \end{equation*}
    \end{enumerate}
    
    \noindent\textit{A probability space, denoted by $(\Omega,\mathcal{F}, P)$, is a set $\Omega$, a $\sigma$-field of subsets $\mathcal{F}$, and a probability measure $P$.}
\end{definition}

\begin{example}
    Suppose we have a rack of $s$ marbles, each of which has a unique integer between $1$ and $s$ painted on it. We will perform an experiment in which we mix up the marbles, choose one at random, write down the number that was on the marble, and place the marble back on the rack. The outcome of this experiment is the number on the marble selected. Now suppose we repeat this experiment $n$ times. Let $N_n(k)$ denote the number of times the ball labeled $k$ was selected during these $n$ trials of the experiment.\par Assume that we had $s=3$ marbles and $n=20$ trials. The outcomes of these 20 trials could be described by listing the numbers which appeared in the order they were observed. A typical result might be 
    
    \begin{equation*}
        1,1,3,2,1,2,2,3,2,3,3,2,1,2,3,3,1,3,2,2,
    \end{equation*}
    
    \noindent in which case 
    
    \begin{equation*}
        N_{20}(1)=5,\quad\quad N_{20}(2)=8, \quad\quad \text{and} \quad\quad N_{20}(3)=7.
    \end{equation*}
    
    \noindent The relative frequencies (i.e., proportion of times) of the outcomes 1, 2, and 3 are then 
    
    \begin{equation*}
        \frac{N_{20}(1)}{20}=.25, \quad\quad \frac{N_{20}(2)}{20}=.40, \quad\quad \text{and} \quad\quad \frac{N_{20}(3)}{20}=.35.
    \end{equation*}
    
    As the number of trials gets large we would expect the relative frequencies $N_{n}(1)/n, \dots, N_{n}(s)/n$ to settle down to some fixed numbers $p_1,\dots,p_s$ (which according to our intuition in this case should all be $1/s$).\par Let us now take a set $\Omega$ having $s$ points that we place in one-to-one correspondence with the possible outcomes of this experiment. In this correspondence exactly one point of $\Omega$ will be associated with the outcome that the ball labeled $k$ is selected. Call that point $\omega_k$. To the point $\omega_k$ we associate the number $p_k=1/s$ and call it the probability of $\omega_k$.\par Suppose now that in addition to being labeled 1 to $s$ the first $r$ marbles are colored red and the remaining $s-r$ are colored black. According to the relative frequency interpretation, the probability of obtaining a red marble is $r/s$. Now suppose $A$ is the event that a red marble is chosen and $B$ is the event that an even numbered marble is chosen. Then to the set $A\cup B$, we assign the probability $P(A\cup B)=j/s$ provided that $\abs{A\cup B}=j$. \par In summary, our probability space for this experiment is a set $\Omega$ having $s$ many points, a collection $\mathcal{F}$ which is equal to the powerset of $\Omega$ and a probability measure that assigns to the event $A$ the probability $P(A)=j/s$ if $A$ has exactly $j$ many points.
\end{example}

\begin{remark}
    There is one very important thing that we must comment on before continuing. That is the difference between relative frequency and probability measure. As we saw earlier, the relative frequency of an outcome is the number of times the outcome occurred divided by the number of trials. It can be shown experimentally that as the number of trials increases, the relative frequency of each outcome tends to get very close to equaling each other and this happens far more often the larger the number of trials gets. 
\end{remark}

\section{Conditional Probability}

Suppose a box contains $r$ red balls labeled $1, 2, \dots, r$ and $b$ black balls labeled $1, 2, \dots, b$. Assume the probability of drawing any particular ball is $(b+r)^{-1}$. If the ball drawn from the box is known to be red, what is the probability that it was the red ball labeled 1? Another way of stating this problem is as follows. Let $A$ be the event that the selected ball was red, and let $B$ be the event that the selected ball was labeled 1. The problem is then to determine the conditional probability that the event $B$ occurred given that the event $A$ occurred. This leads us to the following definition:

\begin{definition}
    \textit{Let $A$ and $B$ be two events such that $P(A)>0$. Then the conditional probability of $B$ given $A$, written $P(B\mid A)$, is defined to be} 
    
    \begin{equation*}
        P(B\mid A)=\frac{P(B\cap A)}{P(A)}.
    \end{equation*}
\end{definition}

 The intuition behind this definition is as follows. Consider an experiment that is repeated a large number of times. Let the number of times the events $A$, $B$, and $A\cap B$ occur in $n$ trials of the experiment be denoted $N_n(A)$, $N_n(B)$, and $N_n(A\cap B)$, respectively. For large values of $n$ we expect $N_n(A)/n$, $N_n(B)/n$, and $N_n(A\cap B)/n$ to be close to $P(A)$, $P(B)$, and $P(A\cap B)$, respectively. Now suppose we record each time the event $A$ occurs in the $n$ trials of the experiment. Then we would have recorded $N_n(A)$ many outcomes. Of these $N_n(A)$ outcomes, the event $B$ occurs $N_n(A\cap B)$ many times. Thus, the proportion of times that $B$ occurs among these $N_n(A)$ outcomes is $N_n(A\cap B)/N_n(A)$. But
 
 \begin{equation*}
     \frac{N_n(A\cap B)}{N_n(A)}=\frac{N_n(A\cap B)/n}{N_n(A)/n},
 \end{equation*}
 
 \noindent and thus for large values of $n$, we have that 
 
 \begin{equation*}
     \frac{N_n(A\cap B)/n}{N_n(A)/n}\approx \frac{P(A\cap B)}{P(A)}.
 \end{equation*}
 
 Now let us try and solve the problem posed at the beginning of Section 3. We have that the set $\Omega$ contains $b+r$ many points each of which carries the probability $(b+r)^{-1}$. Thus, the probability of selecting a red ball is equal to $P(A)=r(b+r)^{-1}$ since there are $r$ many ways to select a red ball and each of those ways has a individual probability of $(r+b)^{-1}$, as stated earlier. Moreover, since there is only one ball which is both red \textit{and} labeled 1, then the set $A\cap B$ has only one point in it. Thus, $P(A\cap B)=1(b+r)^{-1}=(b+r)^{-1}$. And so what is the probability that the ball selected is labeled 1 \textit{given that} it is a red ball? The answer to this is now simple. It is equal to $P(B\mid A)$. Thus, we have that
 
 \begin{equation*}
    P(B\mid A) =\frac{P(A\cap B)}{P(A)} 
    = \frac{(b+r)^{-1}}{r(b+r)^{-1}} 
    = \frac{1}{r}.
 \end{equation*}
 
 \noindent Note that the probability of selecting a ball labeled 1, or rather the probability assigned to the event $B$ is $P(B)=2(b+r)^{-1}$ since there are two balls out of $b+r$ many balls which are labeled 1. Take a moment to reflect on the difference between $P(B\mid A)$ and $P(B)$.

\begin{example}
    Suppose that the population of a certain city is 40$\%$ male and 60$\%$ female. Suppose also that 50$\%$ of the males and 30$\%$ of the females smoke. Find the probability that a smoker is male.\par Let $M$ denote the event that the person selected is a male and let $F$ denote the event that the person selected is female. Also, let $S$ denote the event that the person selected is a smoker and let $N$ denote the event that the person selected is not a smoker. With the given information we can calculate the following probabilities. The first being the probability that a person is a smoker given that the person is male. This is simply
    
    \begin{equation}
        P(S\mid M)=\frac{P(S\cap M)}{P(M)}=\frac{(0.5)(0.4)}{(0.4)}=0.5.
    \end{equation}
    
    The intuition behind the numerator is that we know $40\%$ of the population is male, and $50\%$ of the males are smokers. Thus, the chances of selecting a someone who is both male and a smoker is $(0.5)(0.4)$. Similarly, we can calculate 
    
    \begin{equation}
        P(S\mid F)=\frac{P(S\cap F)}{P(F)}=\frac{(0.3)(0.6)}{(0.6)}=0.3.
    \end{equation}
    
    \noindent We also have that $P(M)=0.4$ and $P(F)=0.6$. What we are trying to find is the conditional probability that if a selected person is a smoker, then what are the chances they are male. Thus, we need to calculate 
    
    \begin{equation*}
        P(M\mid S)=\frac{P(S\cap M)}{P(S)}.
    \end{equation*}
    
    \noindent By multiplying both sides of Equation (1) by $P(M)$, we get a new equality stating $P(S\cap M)=P(M)P(S\mid M)=(0.4)(0.5)=0.2$. Additionally, since we are assuming that a person cannot be both male and female simultaneously, then it follows that $M\cap F=\varnothing$ and $S=(S\cap M)\cup(S\cap F)$. Thus, 
    
    \begin{equation}
        P(S)=P\bigg((S\cap M)\cup(S\cap F)\bigg)=P(S\cap M)+P(S\cap F).
    \end{equation}
    
    Multiplying both sides of Equation (2) by $P(F)$, we get a new equality stating $P(S\cap F)=P(F)P(S\mid F)=(0.6)(0.3)=0.18$. Having already calculated $P(S\cap M)$, we then obtain that
    
    \begin{equation}
        P(S)=P(S\cap M)+P(S\cap F)=(0.2)+(0.18)=0.38.
    \end{equation}
    
    \noindent Thus, 
    
    \begin{equation*}
        P(M\mid S)= \frac{P(S\cap M)}{P(S)}=\frac{0.2}{0.38}\approx 0.53.
    \end{equation*}
    
    \noindent Hence, if one randomly chooses a person from this city and this person happens to be a smoker, then there is approximately a 53$\%$ chance that they are a male.
\end{example}

The problem discussed in this example is a special case of the following general situation. Suppose $A_1, \dots, A_n$ are $n$ mutually disjoint events with union $\Omega$. Let $B$ be an event such that $P(B)>0$ and suppose $P(B\mid A_k)$ and $P(A_k)$ are specified for all $k=1,\dots, n$. What is $P(A_i\mid B)$? To solve this problem note that the $A_k$ are all disjoint and their union is $\Omega$ and consequently

\begin{equation*}
    B=B\cap(\Omega)=B\cap\bigg(\bigcup_{k=1}^{n}A_k\bigg)=\bigcup_{k=1}^{n}(B\cap A_k).
\end{equation*}

\noindent Thus, 

\begin{equation*}
    P(B)=P\bigg(\bigcup_{k=1}^{n}(B\cap A_k)\bigg)=\sum_{k=1}^{k}P(B\cap A_k).
\end{equation*}

\noindent By the same manipulation seen in Example 3.1, we have that 

\begin{equation*}
    P(B\cap A_k)=P(A_k)P(B\mid A_k),
\end{equation*}

\noindent so we can write 

\begin{equation}
    P(A_i\mid B)=\frac{P(A_i\cap B)}{P(B)}=\frac{P(A_i)P(B\mid A_i)}{\sum_{k=1}^{n}P(A_k)P(B\mid A_K)}.
\end{equation}

This formula, called \textit{Bayes' Rule}, finds frequent application. One way of looking at Equation (5) is as follows. Suppose we think of the events $A_k$ as being the possible ``causes'' of the observable event $B$. Then $P(A_i\mid B)$ is the probability that the event $A_i$ was the cause of $B$ given that $B$ occurs. Below we will conclude this paper with the solution to the problem posed at the very beginning and we will solve it using Bayes' Rule.

\begin{solution}
    We can think of a probability space being constructed in which events $A_1, A_2$, and $A_3$ correspond, respectively, to the first, second, and third chest being selected. These events are disjoint and their union is the whole space $\Omega$ since only one chest is selected. We assume that each chest is equally likely of being chosen and so $P(A_i)=1/3$ for $i=1,2,3$. Let $B$ be the event that the coin observed was gold. Then, from the composition of the chests it follows that 
    
    \begin{align}
        P(B\mid A_1)&=1, &P(B\mid A_2)=1/2&, &P(B\mid A_3)=0&.
    \end{align}
    
    \noindent The intuition here is that the probability of observing a gold coin given that the first chest is selected (i.e., event $A_1$) is 1 since both drawers contain a gold coin. The probability of observing a gold coin given that the second chest is selected (event $A_2$) is 1/2 since there is only one gold coin but two drawers. Lastly, the probability that a gold coin is observed given that the third chest is selected (event $A_3$) is 0 since neither drawer contains a gold coin. The problem asks for the probability that the second drawer of the selected chest has a gold coin given that a gold coin was observed in the first drawer. This can only happen if the first chest is selected. Thus, the problem is equivalent to finding $P(A_1\mid B)$. Thus, 
    
    \begin{equation*}
        \begin{split}
            P(A_1\mid B)&=\frac{P(A_1\cap B)}{P(B)} \\
            &=\frac{P(A_1)P(B\mid A_1)}{\sum_{k=1}^{3}P(A_k)P(B\mid A_k)} \\
            &= \frac{(\frac{1}{3})(1)}{(\frac{1}{3})(1)+(\frac{1}{3})(\frac{1}{2})+(\frac{1}{3})(0)} \\
            &= \frac{2}{3}.
        \end{split}
    \end{equation*}
    
    So how do we interpret this? Having selected a chest and then observing a gold coin in one of the drawers, we needed to find the likely-hood that the second drawer also contained a gold coin. We know that it would have been guaranteed if the chest that was selected was the first. Thus, given that a gold coin was observed, what are the chances that the first chest was selected? Well if $B$ denotes the event that a gold coin was observed, then it as a set, contains all the ways in which a gold coin can be observed. Namely, selecting the first chest and opening up any one of the two drawers (this corresponds to two points in $B$) or selecting the second chest and opening up the one with a gold coin (this correspond to another point in $B$). And so we are wondering, among the three points in $B$, how many of those points coincide with the event $A_1$? Well, 2 points in $B$ coincide with $A_1$. Thus, the proportion of times that $A_1$ occurs among all the points in $B$ is 2/3.
\end{solution}

\section{Independence}

    We will begin this section with a motivating example. The following example is called \textit{Polya's Urn Scheme}. Suppose an urn has $r$ red balls and $b$ black balls. A ball is drawn and its color noted. Then it together with $c>0$ balls of the same color as the drawn ball are added to the urn. The procedure is repeated $n-1$ additional times so that the total number of balls drawn from the urn is $n$.\par Let $R_1$ denote the event that the first ball drawn is red. Let $B_1$ denote the event that the first ball drawn is black. Note that $R_1\cap B_1=\varnothing$ since only one ball is drawn at a time. Further, there are $r+b$ balls and each has a probability of $(r+b)^{-1}$ of being chosen. What is $P(R_1\cap R_2)$? Recall that 
    
    \begin{equation*}
        P(R_2\mid R_1)=\frac{P(R_1\cap R_2)}{P(R_1)}\Leftrightarrow P(R_1\cap R_2)=P(R_1)P(R_2\mid R_1).  
    \end{equation*}
    
    If the first ball drawn is red, then it along with $c$ more red balls would be placed back into the urn. This leaves $r+b+c$ balls in the urn at the time that the second ball is drawn. Note that each ball has $(r+b+c)^{-1}$ chance of being drawn. However, $P(R_2)=(r+c)(r+b+c)^{-1}$ and $P(B_2)=b(r+b+c)^{-1}$. Thus 
    
    \begin{equation*}
        P(R_1\cap R_2)=\bigg(\frac{r}{r+b}\bigg)\bigg(\frac{r+c}{r+b+c}\bigg).
    \end{equation*}
    
    Now consider $P(B_1\cap R_2)$. We have that 
    
    \begin{equation*}
        P(B_1\cap R_2)=\bigg(\frac{b}{r+b}\bigg)\bigg(\frac{r}{r+b+c}\bigg).
    \end{equation*}
    
    Note that if we add these together we get
    
    \begin{equation*}
        \begin{split}
            P(R_2)&=P(R_1\cap R_2)+P(B_1\cap R_2) \\
            &=\bigg(\frac{r}{r+b}\bigg)\bigg(\frac{r+c}{r+b+c}\bigg)+\bigg(\frac{b}{r+b}\bigg)\bigg(\frac{r}{r+b+c}\bigg) \\
            &=\frac{r(r+c)+rb}{(r+b)(r+b+c)}\\
            &= \frac{r(r+b+c)}{(r+b)(r+b+c)} \\
            &= \frac{r}{r+b} \\
            &= P(R_1).
        \end{split}
    \end{equation*}
    
    Consequently,
    
    \begin{equation*}
        P(B_2)=\frac{b}{r+b}=P(B_1).
    \end{equation*}
    
    \noindent The interpretation of this result might be a little difficult to decode, but we will now discuss the concept of independence and see the previous situation in a more general light.\par Consider a box having four distinct balls and an experiment consisting of selecting a ball from the box. We assume that the balls are equally likely to be drawn. Let $\Omega=\{1,2,3,4\}$ and assign probability $1/4$ to each point.\par Let $A$ and $B$ be two events. For some choices of $A$ and $B$, knowledge that $A$ occurs increases the odds that $B$ occurs. For example, if $A=\{1,2\}$ and $B=\{1\}$, then $P(A)=1/2$, $P(B)=1/4$, and $P(A\cap B)=1/4$. However, $P(B\mid A)=P(A\cap B)/P(A)=(1/4)/(1/2)=1/2$. On the other hand, suppose that $A=\{1,2,3\}$ and $B=\{1,2,4\}$. Then $P(A)=3/4$, $P(B)=3/4$, $P(A\cap B)=1/2$, and $P(B\mid A)=P(A\cap B)/P(A)=2/3$ which is less than $P(B)$.\par Things become interesting when the conditional probability is equal to the unconditional probability. For example, let $A=\{1,2\}$ and $B=\{1,3\}$. Then $P(A)=1/2$, $P(B)=1/2$, $P(A\cap B)=1/4$, and $P(B\mid A)=1/2$. Events such as these in which the conditional and unconditional probabilities are equal are said to be \textit{independent}. This leads us to a more common definition of the concept.
    
    \begin{definition}
        \textit{Two events $A$ and $B$ are independent if and only if}
        
        \begin{equation*}
            P(A\cap B)=P(A)P(B).
        \end{equation*}
    \end{definition}
    
    \noindent In general we define $n\geq 3$ events $A_1, \dots, A_n$ to be mutually independent if 
    
    \begin{equation*}
        P(A_1\cap\cdots\cap A_n)=P(A_1)\cdots P(A_n).
    \end{equation*}
    
    \begin{example}
        Let $S$ be the square $0\leq x\leq 1$, $0\leq y\leq 1$ in the plane. Consider the uniform probability space space on the square, and let $A$ be the event 
        
        \begin{equation*}
            \{(x,y)\colon 0\leq x\leq 1/2, 0\leq y\leq 1\}
        \end{equation*}
        
        \noindent and $B$ be the event 
        
        \begin{equation*}
            \{(x,y)\colon 0\leq x\leq 1, 0\leq y\leq 1/4\}.
        \end{equation*}
        
        \noindent Show that $A$ and $B$ are independent events. To show this we must show that $P(A\cap B)=P(A)P(B)$. Thus, let us compute $P(A\cap B)$. It follows that the intersection is 1/4 of 1/2 and this is precisely equal to $P(A)P(B)=(1/4)(1/2)=1/8$. Thus, these events are independent as asserted.
    \end{example}
    
    In an experiment such as tossing a coin $n$ times, where success and failure at each toss occur with probabilities $p$ and $1-p$ respectively, we intuitively believe that the outcome of the $i$th toss should have no influence on the outcomes of the other tosses. We now wish to construct a probability space corresponding to the compound experiment of an $n$-fold repetition of our simple given experiment that incorporates our intuitive beliefs. \par Since each of the $n$ trials can result in either success or failure, there is a total of $2^n$ possible outcomes to the compound experiment since of all the $n$ tosses, they can each be one of 2 different values. These may be represented by an $n$-tuple $(x_1,\dots,x_n)$, where $x_i=1$ or 0. We take the set $\Omega$ to be the collection of all such $n$-tuples (i.e., $\{0,1\}^n$). The $\sigma$-field $\mathcal{F}$ is taken to be all subsets of $\Omega$, (i.e., $\mathcal{P}(\{0,1\}^n)$). \par We now come to the assignment of a probability measure. To do this it is only necessary to assign probabilities to the $2^n$ one point sets $\{(x_1, \dots,x_n)\}$. Suppose the $n$-tuple is such that exactly $k$ of the $x_i$'s have the value 1; for simplicity, say $x_1=x_2=\cdots=x_k=1$ and the other $x_i$'s have value 0. Then $A_i$ denotes the event that the $i$th trial, $1\leq i\leq n$, is a success, we see that 
    
    \begin{equation*}
        \{(1,1,\dots,1,0,\dots,0)\}=A_1\cap\cdots\cap A_k\cap A_{k+1}^c\cap\cdots\cap A_{n}^c.
    \end{equation*}
    
    \noindent To explain further, the event $A_1$ represents all the $n$-tuples in which the first toss is a success. Similarly, $A_k$ is the collection of all $n$-tuples in which the $k$th toss is a success. Thus, the set $A_1\cap A_2$ is the set of all $n$-tuples in which the first and second tosses are a success. According to our intuition, the events $A_1, \dots, A_k, A_{k+1}^c, \dots, A_n^c$ are to be mutually independent and $P(A_i)=p$, $1\leq i\leq n$. Thus we should assign $P$ so that 
    
    \begin{equation*}
        \begin{split}
            P\big(\{(1,1,\dots,1,0,\dots,0)\}\big) &= P(A_1)\cdots P(A_k)P(A_{k+1}^c)\cdots P(A_n^c) \\
            &= p^k(1-p)^{n-k}.
        \end{split}
    \end{equation*}
    
    Let us now compute the probability that exactly $k$ of the $n$ trials result in a success. Note carefully that this situation differs from the probability that $k$ \textit{specified} trials result in a success and the other $n-k$ trials result in failures. Let $B_k$ denote the event that exactly $k$ of the $n$ trials are successes. Since we have just shown that every instance of a sequence having a specified group of $k$ successes carries with it a probability of $p^k(1-p)^{n-k}$, this combined with the fact that there are $C(k,n)$ many $n$-tuples in which there are $k$ successes, then it follows that 
    
    \begin{equation*}
        P(B_k)=\binom{n}{k}p^k(1-p)^{n-k}.
    \end{equation*}
    
    Let us explore this concept through the following example.
    
    \newpage
    
    \begin{example}
        Suppose a machine produces bolts, $10\%$ of which are defective. Find the probability that a box of 3 bolts contains at most one defective bolt.\par To solve this problem we can think of the production of 3 bolts as a 3-fold compound experiment in which each trial can result in either success or failure. Then we will let $\Omega$ be the set of all 3-tuples, $\{0,1\}^3$. Let $A_0$ denote the event that none of the bolts are defective and let $A_1$ denote the event that exactly one bolt is defective. Then $A_0\cup A_1$ is the event that \textit{at most} one bolt is defective. Since $A_0$ and $A_1$ are disjoint, it follows that 
        
        \begin{equation*}
            \begin{split}
                P(A_0\cup A_1) &= P(A_0)+P(A_1) \\
                &= \binom{3}{0}(0.1)^0(0.9)^3+\binom{3}{1}(0.1)^1(0.9)^2 \\
                &= (0.9)^3+3(0.1)(0.9)^2 \\
                &= 0.972.
            \end{split}
        \end{equation*}
        
        Now let us find the probability that exactly one bolt is defective in a box of three bolts. To do this we will let $A_1\subset\Omega$ be an event denoting the outcomes in which exactly one of the bolts is defective. Since these three bolt boxes are represented by 3-tuples, we can list out each outcome in $A_1$. These would be $(1,0,0)$, $(0,1,0)$, and $(0,0,1)$. It follows then that the probability of there being exactly one defective bolt is $0.10$ 
        
    \end{example}
    




\end{document}